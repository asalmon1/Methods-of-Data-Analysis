---
title: 'STOR 455 Homework #3'
subtitle: 40 points - Due 2/21 at 5:00pm
output:
  pdf_document: default
---
Audrey Salmon

__Directions:__ You will be assigned to a group of four to five students for this assignment. Parts 1, 2, 3, & 6 should be submitted individually to Gradescope by each student in your group (although you should work together on these parts). Parts 4 & 5 should be submitted as a group to Gradescope. There are separate places to submit the individual and group portions of the assignment. 
    
__Situation:__ Can we predict the selling price of a house in Ames, Iowa based on recorded features of the house? That is your task for this assignment. Each group will have a dataset with information on forty potential predictors and the selling price (in $1,000’s) for a sample of homes. The data set for your group is in AmesTrain??.csv (where ?? corresponds to your group number) and can be found in the AmesTrain zipped file under class 14 in Canvas. A separate file identifies the variables in the Ames Housing data and explains some of the coding.

```{r}
library(tidyverse)
library(car)
library(corrplot)
library(leaps)
source("https://raw.githubusercontent.com/JA-McLean/STOR455/master/scripts/ShowSubsets.R")

HouseData <- read_csv('AmesTrain3.csv', show_col_types = FALSE)
columns_to_exclude <- c("LotConfig", "HouseStyle", "ExteriorQ", "ExteriorC", "Foundation", "BasementHt", "BasementC", "BasementFin", "Heating", "HeatingQC", "CentralAir", "KitchenQ", "GarageType", "GarageQ", "GarageC", "Order")
HouseData1 <- HouseData[, !names(HouseData) %in% columns_to_exclude]
```

### Part 1. Build an initial “basic” model    
Your basic model can use any of the quantitative variables in the dataset but should NOT use the categorical variables or transformations. Use your data to select a set of predictors to include in your model, utilizing at least two model selection methods (e.g. don’t just check all subsets, although it will work well here, this method will fail in future assignments). You **should not** show all of the output for every model you consider, but you should give a clear description of the path you took and the criteria that you used to compare competing models.

Include the following information for this initial choice of a model:

* the summary() output for your model
* comments on which (if any) of the predictors in the model are not significant at a 5% level
* comments on what the VIF values tell you about the individual predictors in your model
    
Do not consider the Order variable (that is just an observation number) as one of your predictors. Avoid predictors that are exactly related. For example, if GroundSF=FirstSF+SecondSF you will likely get trouble if you try to put all three in the same model. 

```{r}
all <- regsubsets(Price ~ ., data = HouseData1, nvmax=26)
#print.data.frame(ShowSubsets(all))
```

```{r}
# Fit the full model
Full <- lm(Price ~ ., data = HouseData1)
# Find the MSE for the full model
MSE <- (summary(Full)$sigma)^2
# Start with a model with NO predictors
none <- lm(Price ~ 1, data = HouseData1)
# Don’t specify a direction
step(none, scope = list(upper = Full), scale = MSE, trace = FALSE)
```

```{r}
fullmodel <- lm(Price ~ Quality + GroundSF + BasementFinSF + LotArea + YearBuilt + GarageSF + BasementSF + YearRemodel + LotFrontage + Fireplaces + HalfBath + Condition + Bedroom + TotalRooms + ScreenPorchSF + EnclosedPorchSF, data = HouseData1)
reducedmodel <- lm(Price ~ Quality + GroundSF + BasementFinSF + LotArea + YearBuilt + GarageSF + BasementSF + YearRemodel + LotFrontage + Fireplaces + Condition + Bedroom + TotalRooms, data = HouseData1)
anova(fullmodel, reducedmodel)
```

I decided to use a model with 13 predictors. In order to decide how many predictors to include, I first utilized ShowSubsets() to see the best model for every possible number of predictors, and to see the adjusted R squared and Mallow's Cp for each of those models. I was still not certain how many predictors to choose, so I decided to also use stepwise regression to determine the best model. I think this is a decent strategy as it considers whether predictors already in the model can be dropped. I ultimately decided to choose the model that R determined was the best through stepwise regression, which is the 17-predictor model. I thought it would make sense when considering the first method as well, as it seems that any model between 10 and 20 predictors could be appropriate. This model had a relatively high adjusted R squared (0.8603). However, when I looked at the VIF values, I noticed that FirstSF and SecondSF both had pretty high values. I think this makes sense as those are  pretty closely related. I know that FirstSF + SecondSF = GroundSF (as those are just the square footages of the first and second floors, which obviously add to the total square footage.) For simplicity's sake, I decided to replace those two predictors with just GroundSF. So I then had a model with 16 predictors. Yet, looking at this model, three of the predictors were not significant at the 0.05 level. So, I thought I might remove those three predictors, and use an F-test to see if I should reject the 13-predictor reduced model in favor of the 16-predictor full model. I took H0 = the reduced model, and HA = the full model. The F-test resulted in a p-value of 0.078, which is > 0.05, so in this case I failed to reject the null and kept the reduced model as my final model for this question.

```{r}
mod1 <- reducedmodel
summary(mod1)
vif(mod1)
```

In terms of the final model, which I have called "mod1" above, all of the predictors are significant at a 0.05 level. The VIF values for each predictor are all < 5, with the largest being GroundSF having a VIF of 4.697278. This is close to 5, so it suggests that there is some correlation between this predictor and some of the other predictors, but not so much that I am concerned about multicollinearity. Finally, the adjusted R-squared is 0.8594, which is slightly lower than the 17-predictor model I created using stepwise regression. However, the difference between 0.8603 and 0.8594 is so small that, in my opinion (and as indicated by the F-test), it is a better practice to use the smaller, more simple model.

### Part 2. Residual analysis for your "basic" model    

Perform a residual analysis for the model you chose in Part 1. Include any plots relevant to checking model conditions - with interpretations. Also check whether any of the data cases are unusual with respect to standardized/studentized residuals. Since there are a lot of data points don’t worry about the “mild” cases for residuals, but indicate what specific criteria you are using to identify “unusual” points. 

```{r}
plot(mod1)
```

So, I will first interpret these various residual plots. The normal quantile plot shows that the residuals follow a somewhat normal distribution, with some very extreme values at both ends - these appear to be at indices 179, 222, and 343. This means the distribution of residuals has long tails on both ends, but it doesn't seem that it would be very skewed as there are some very large and some very small residuals. The residuals vs. fitted plot shows a curved line, rather than straight, which indicates that a linear model may not be the best fit for the relationship between these variables. The scale-location plot also shows a curve, which, along with the varying spread in the residuals vs. fitted plot, indicates that there is not a constant variance among the residuals. The residuals vs. leverage plot shows that there is one observation, number 179 which lies beyond Cook's Distance, and two others (again, 343 and 222) lie close. So, 179 is the only significantly influential observation.

```{r}
top_resid_data <- order(abs(mod1$residuals), decreasing = TRUE)[1:15]
Resids <- mod1$residuals[top_resid_data]
StanResid <- rstandard(mod1)[top_resid_data]
StudResid <- rstudent(mod1)[top_resid_data]
StanResid
StudResid
```

So, I looked at the 15 largest (positive or negative) residuals for this data. I thought that I would create a new model, removing the data points corresponding to the first 10 largest, as those all have studentized and standardized residuals > 3, which means I can reasonably classify them as outliers.

```{r}
indices <- c(343, 222, 109, 78, 319, 380, 292, 351, 588, 179)
HouseData2 <- HouseData1 %>%
  slice(-indices)
```

Adjust your model (either the predictors included or data values that are used to fit it, but not yet using transformations) on the basis of your residual analysis – but don’t worry too much about trying to get all of the conditions “perfect”.  For example, don’t automatically just delete any points that might give large residuals! If you do refit something, be sure to document what changed and include the new summary() output.

Using the new dataframe I created without the observations that have the largest residuals, I thought I would run stepwise regression again to see if that would make a difference on the predictors.

```{r}
# Fit the full model
Full <- lm(Price ~ ., data = HouseData2)
# Find the MSE for the full model
MSE <- (summary(Full)$sigma)^2
# Start with a model with NO predictors
none <- lm(Price ~ 1, data = HouseData2)
# Don’t specify a direction
step(none, scope = list(upper = Full), scale = MSE, trace = FALSE)
```

Clearly, this did have a very large difference on the model chosen by R's stepwise regression, as this new suggested model has only 13 predictors. However, yet again, I noticed that one of the predictors in this model (Fireplaces) was not significant at a 0.05 level. So, I thought I would run an F-test again, taking Fireplaces out of the reduced model.

```{r}
fullmodel1 <- lm(formula = Price ~ Quality + GroundSF + BasementFinSF + BasementSF + 
    LotArea + YearBuilt + GarageSF + YearRemodel + Bedroom + 
    LotFrontage + FullBath + Fireplaces + Condition, data = HouseData2)
reducedmodel1 <- lm(formula = Price ~ Quality + GroundSF + BasementFinSF + BasementSF + 
    LotArea + YearBuilt + GarageSF + YearRemodel + Bedroom + 
    LotFrontage + FullBath + Condition, data = HouseData2)
anova(reducedmodel1, fullmodel1)
```

I took H0 = the reduced model, and HA = the full model. The F-test resulted in a p-value of 0.05045, which is > 0.05, so in this case I failed to reject the null and decided to keep the reduced model as my final model.

```{r}
mod2 <- reducedmodel1
summary(mod2)
vif(mod2)
```

For this 12-predictor model with large outliers removed, all of the predictors are significant at a 0.05 level. The adjusted R squared is 0.8875, and none of the predictors have VIF values > 5, so I am not concerned about multicollinearity. Interestingly, the VIF of GroundSF (which had a VIF very close to 5 in the first model) decreased a lot! I think this probably means that GroundSF has a high level of correlation with Fireplaces, which makese sense as most houses will have a fireplace (if they have one at all) on the first floor.

### Part 3. Prediction for your "basic" model

Suppose that you are interested in a house in Ames that has the characteristics listed below. Construct a 95% confidence interval for the mean price of such houses.

A 2 story 11 room home, built in 1987 and remodeled in 1999 on a 21540 sq. ft. lot with 328 feet of road frontage. Overall quality is good (7) and condition is average (5). The quality and condition of the exterior are both good (Gd) and it has a poured concrete foundation. There is an 757 sq. foot basement that has excellent height, but is completely unfinished and has no bath facilities. Heating comes from a gas air furnace that is in excellent condition and there is central air conditioning. The house has 2432 sq. ft. of living space above ground, 1485 on the first floor and 947 on the second, with 4 bedrooms, 2 full and one half baths, and 1 fireplace. The 2 car, built-in garage has 588 sq. ft. of space and is average (TA) for both quality and construction. The only porches or decks is a 205 sq. ft. open porch in the front. 

```{r}
one_house <- data.frame(TotalRooms = 11, YearBuilt = 1987, YearRemodel = 1999, 
                        LotArea = 21540, LotFrontage = 328, Quality = 7, Condition = 5, 
                        BasementUnFinSF = 757, BasementFinSF = 0, BasementSF = 757, 
                        GroundSF = 2432, FirstSF = 1485, SecondSF = 947, Bedroom = 4, 
                        FullBath = 2, HalfBath = 1, Fireplaces = 1, GarageSF = 588, 
                        GarageCars = 2, OpenPorchSF = 205, EnclosedPorchSF = 0, 
                        ScreenPorchSF = 0)
predict.lm(mod2, one_house, interval = 'confidence', level = 0.95)
```

So, we are 95% confident that the true mean price for all houses with the above characteristics lies between \$269,586.60 and \$305,488.80
    
### Part 4: Find a “better" model:    
    
In addition to the quantitative predictors from Part 1, you may now consider models with:     

* Transformations of predictors. You can include functions of quantitative predictors. Probably best to use the I() notation so you don’t need to create new columns when you run the predictions for the test data. For example:      lm(Price~LotArea+I(LotArea^2)+sqrt(LotArea)+log(LotArea),... 
* Transformations of the response. You might address curvature or skewness in residual plots by transforming the response prices with a function like log(Price ), sqrt(Price), Price^2, etc..  These should generally not need the I( ) notation to make these adjustments.
* Combinations of variables. This might include for example creating a new variable which would count the total bathrooms in the house in a single predictor.  
Do not haphazardly use transformation on predictors, but examine the relationships between the predictors and response to determine when a transformation would be warranted. Again use multiple model selection methods to determine a best "better" model, but now with transformed variables as possible predictors in the model. You should determine useful transformations **prior** to using the model selection methods.

```{r}
HouseData2$TotalPorchSF <- 
  HouseData2$OpenPorchSF + HouseData2$EnclosedPorchSF+ HouseData2$ScreenPorchSF
HouseData2$sqrt_LotArea <- sqrt(HouseData2$LotArea)
HouseData2$sqr_BasementUnFinSF <- HouseData2$BasementUnFinSF^2

#plot(Price ~ ., data = HouseData2)
```

```{r}
# Fit the full model
Full <- lm(log(Price) ~ ., data = HouseData2)
# Find the MSE for the full model
MSE <- (summary(Full)$sigma)^2
# Start with a model with NO predictors
none <- lm(log(Price) ~ 1, data = HouseData2)
# Don’t specify a direction
step(none, scope = list(upper = Full), scale = MSE, trace = FALSE)
```

```{r}
mod3 <- lm(log(Price) ~ Quality + GroundSF + YearBuilt + sqrt_LotArea + 
    Condition + BasementSF + TotalPorchSF + Fireplaces + GarageCars + 
    sqr_BasementUnFinSF + YearRemodel + FullBath, data = HouseData2)
summary(mod3)
vif(mod3)
```

__Discuss the process that you used to transform the predictors and/or response__ so that you could use this process in the future on a new data set. This discussion will carry the bulk of your grade for this part.

The first thing we noticed when looking at the different plots is that several of the predictors - YearRemodel, YearBuilt, BasementFinSF, BasementUnFinSF, GroundSF, and a few others all seemed to have an exponential relationship with Price. Typically, the way we find a good model for a relationship like that is taking the natural log of the response variable, so we decided to take the log of Price in our model. Looking at the residual plots, taking the log of Price made the residuals significantly more normal, based on the normal quantile plot. We also created a variable for the total square footage of the porch, by adding OpenPorchSF + EnclosedPorchSF + ScreenPorchSF, as we thought that the overall size of the porch would correlate better with the price of the house rather than looking at the different kinds of porches (and some houses have a larger porch composed of multiple kinds). Finally, we took the square root of LotArea and squared BasementUnFinSF, as this resulted in a more linear-seeming relationship between those two variables and Price.

### Part 5. Residual analysis for your fancier model   

Repeat the residual analysis from Part 2 on your new model constructed in Part 4. A residual analysis was likely (hopefully) part of your process for determining your "better" model. That does not need to be fully repeated here. You should include any plots relevant to checking model conditions - with interpretations, as well as discussing whether any of the data cases are unusual with respect to standardized/studentized residuals. Make sure to indicate what specific criteria you are using to identify “unusual” points.

```{r}
plot(mod3)
```

 The normal quantile plot shows that the residuals follow a somewhat normal distribution, with some  extreme values at both ends. This means the distribution of residuals has longer tails on both ends, but it doesn't seem that it would be very skewed as there are some very large and some very small residuals. otherwise, though, the data forms a very straight line, so besides the few outliers the data is very normally distributed. The residuals vs. fitted plot shows a much straighter line than the first model we created, which indicates that this model is a good fit for the data, and there are likely not any major issues or hidden trends within the data. The scale-location plot shows a slight curve, but it is also less than the same plot for our original model. This, along with the fairly constant spread in the residuals vs. fitted plot, indicates that there is a mostly constant variance among the residuals. The residuals vs. leverage plot shows that there is one observation, number 294, which lies beyond Cook's Distance. So, 294 is the only significantly influential observation.

```{r}
top_resid_data1 <- order(abs(mod3$residuals), decreasing = TRUE)[1:10]
Resids1 <- mod3$residuals[top_resid_data1]
StanResid1 <- rstandard(mod3)[top_resid_data1]
StudResid1 <- rstudent(mod3)[top_resid_data1]
StanResid1
StudResid1
```

So, we looked at the 10 largest (positive or negative) residuals for this data. We decided to create a new dataframe, removing the data points corresponding to the 4 largest, as those all have studentized residuals with an absolute value > 3. These are classed as outliers (especially observation 294!)

```{r}
indices <- c(294, 449, 236, 130, 44)
HouseData3 <- HouseData2 %>%
  slice(-indices)
```

```{r}
# Fit the full model
Full <- lm(log(Price) ~ ., data = HouseData3)
# Find the MSE for the full model
MSE <- (summary(Full)$sigma)^2
# Start with a model with NO predictors
none <- lm(log(Price) ~ 1, data = HouseData3)
# Don’t specify a direction
step(none, scope = list(upper = Full), scale = MSE, trace = FALSE)
```
```{r}
fullmodel1 <- lm(log(Price) ~ Quality + GroundSF + YearBuilt + sqrt_LotArea + 
    BasementSF + Condition + GarageSF + Fireplaces + YearRemodel + 
    TotalPorchSF + sqr_BasementUnFinSF + Bedroom + FullBath + 
    GarageCars + LotArea, data = HouseData3)
summary(fullmodel1)
reducedmodel1 <- lm(log(Price) ~ Quality + GroundSF + YearBuilt + sqrt_LotArea + 
    BasementSF + Condition + GarageSF + Fireplaces + YearRemodel + 
    TotalPorchSF + sqr_BasementUnFinSF + Bedroom, data = HouseData3)
anova(fullmodel1, reducedmodel1)
```

We used stepwise regression to try to find a better model from the data with the outliers removed. Unfortunately, it seemed that four of the predictors were not significant at the 0.05 level (specifically GarageSF, FullBath, GarageCars, and LotArea). So, we decided to use the F-test to see if we could reasonably remove some of them while maintaining a model with approximately the same accuracy. After experimenting a bit (as we realized that removing all four of these predictors would result in a very small p-value), we settled on a reduced model removing three of the less significant predictors: FullBath, GarageCars, and LotArea. We took H0 = the reduced model, and HA = the full model. This resulted in a 0.06185 p-value in our F-test, which is > 0.05, so we failed to reject the null and kept our reduced model (the summary for which is shown below).

```{r}
finalmod <- reducedmodel1
summary(finalmod)
vif(finalmod)
```

Our final model has 13 predictor variables, all of which are significant at the 0.05 level and none of which have concerning (> 5) VIF values. In fact, none are even > 4, so the risk of multicollinearity here is very low. This model also has an adjusted R-squared of 0.9155, which is noticeably higher than past models.

### Part 6. Prediction for your "better" model  

Again suppose that you are interested in a house in Ames that has the characteristics listed below. Construct a 95% confidence interval for the mean price of such houses. Make sure that your interval is in dollars (in $1,000’s) and not transformed units!

A 2 story 11 room home, built in 1987 and remodeled in 1999 on a 21540 sq. ft. lot with 328 feet of road frontage. Overall quality is good (7) and condition is average (5). The quality and condition of the exterior are both good (Gd) and it has a poured concrete foundation. There is an 757 sq. foot basement that has excellent height, but is completely unfinished and has no bath facilities. Heating comes from a gas air furnace that is in excellent condition and there is central air conditioning. The house has 2432 sq. ft. of living space above ground, 1485 on the first floor and 947 on the second, with 4 bedrooms, 2 full and one half baths, and 1 fireplace. The 2 car, built-in garage has 588 sq. ft. of space and is average (TA) for both quality and construction. The only porches or decks is a 205 sq. ft. open porch in the front. 

```{r}
one_more_house <- data.frame(TotalRooms = 11, YearBuilt = 1987, YearRemodel = 1999, 
                             LotArea = 21540, LotFrontage = 328, Quality = 7, Condition = 5, 
                             BasementUnFinSF = 757, BasementFinSF = 0, BasementSF = 757, 
                             GroundSF = 2432, FirstSF = 1485, SecondSF = 947, Bedroom = 4, 
                             FullBath = 2, HalfBath = 1, Fireplaces = 1, GarageSF = 588, 
                             GarageCars = 2, OpenPorchSF = 205, EnclosedPorchSF = 0, 
                             ScreenPorchSF = 0, sqrt_LotArea = sqrt(21540), 
                             TotalPorchSF = 205, sqr_BasementUnFinSF = 573049)
exp(predict.lm(finalmod, one_more_house, interval = 'confidence', level = 0.95))
```

So, we are 95% confident that the true mean price for all houses with the above characteristics lies between \$252,379.90 and \$269,156.50 (note that I used the exp() function to get the prediction in terms of Price rather than log(Price)).

Compare and contrast the two predictions made for the mean price using your "basic" and "better' models.

So, the two predictions in this assignment were surprising to me because the intervals actually did not overlap at all. I think this is likely to do with us removing some outliers and especially some influential points. In my opinion, this final model is likely a better model than my original one when trying to predict house prices, as a few points with high leverage were having a major effect on that original model. In general, when trying to predict the mean price of a house, we probably do not want to consider major outliers because they will have a significant effect on the model and the interval you create from it. Additionally, the confidence interval from the final "better" model is much smaller than the confidence interval for the "basic" model, so I think that overall the "better" model actually is better as it gives us a clearer idea of the mean price for a house with these characteristics. Generally, a more narrow confidence interval indicates a higher degree of precision, thus showing that the final model is better than previous ones.